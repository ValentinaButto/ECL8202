<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Hierarchical Bayesian models</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/spacelab.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>
<link href="libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Hierarchical Bayesian models</h1>

</div>


<p>In this laboratory, we will see how to write a hierarchical Bayesian model in the Stan language.</p>
<div id="data" class="section level1">
<h1>Data</h1>
<p>As in the example using <em>brms</em> in the course notes, we will use the <code>rikz</code> dataset.</p>
<pre class="r"><code>rikz &lt;- read.csv(&quot;../donnees/rikz.csv&quot;)
head(rikz)</code></pre>
<pre><code>##   Sample Richness Exposure    NAP Beach
## 1      1       11       10  0.045     1
## 2      2       10       10 -1.036     1
## 3      3       13       10 -1.336     1
## 4      4       11       10  0.616     1
## 5      5       10       10 -0.684     1
## 6      6        8        8  1.190     2</code></pre>
</div>
<div id="creating-a-stan-model" class="section level1">
<h1>Creating a Stan model</h1>
<p>In RStudio, select <em>File -&gt; New File -&gt; Stan File</em>. RStudio creates a new Stan code file that already contains a sample template. Save the file with the extension <code>.stan</code> (e.g. <code>radon.stan</code>) before continuing.</p>
<p>First, notice that the <code>//</code> symbol is used to denote comments in Stan, unlike R which uses <code>#</code> for the same purpose. Except for these comments, the Stan file created contains three blocks.</p>
<ul>
<li><code>data</code>: Defines the variables that will be supplied to the model as input data.</li>
<li><code>parameters</code>: Defines the variables which must be estimated by the model.</li>
<li><code>model</code>: Defines the statistical model for the data according to the parameters.</li>
</ul>
<p>Most Stan models use at least these three blocks, although other blocks are possible: <code>functions</code>, <code>transformed data</code>, <code>transformed parameters</code> and <code>generated quantities</code>. As in R, the blocks are delimited by curly braces <code>{}</code>.</p>
<p>The <code>model</code> block contains only one instruction, <code>y ~ normal(mu, sigma);</code>, which indicates that <code>y</code> follows a normal distribution with mean <code>mu</code> and standard deviation <code>sigma</code>. In Stan, the symbol <code>~</code> is used to assign a certain probability distribution to a variable (unlike R where this symbol is used to relate the response of a model to the predictors).</p>
<p><em>Note</em>: In Stan, all instructions must end with a semicolon <code>;</code>, except those that start a block (like <code>model</code>).</p>
<div id="declaration-of-variables" class="section level2">
<h2>Declaration of variables</h2>
<p>Unlike R, all the variables appearing in a Stan model must first be “declared”. The first line of <code>data</code>, <code>int&lt;lower=0&gt; N;</code> declares the variable <code>N</code> which is an integer (type <code>int</code>) taking a minimum value of 0. It is important to differentiate the integer variables from variables that can take any real value (type <code>real</code>). The specification of lower or upper bounds is optional for the <code>data</code> elements, but they allow Stan to produce an error if the data supplied to the input does not respect these bounds. In this case, the lower bound should probably be 1 since the data contains at least 1 observation.</p>
<p>The second line of <code>data</code>, <code>vector[N] y;</code> declares the variable <code>y</code> as a vector of <code>N</code> elements. Note that it was important to declare <code>N</code> before using it in the declaration of <code>y</code>. Vectors in Stan work similar to R, except that they can only be composed of real numbers (we will see later how to define the equivalent of a vector for integers).</p>
<p>The <code>parameters</code> block declares two real variables, <code>mu</code> and <code>sigma</code>, the second being constrained to be greater than or equal to 0. It is important to define the minimum and maximum possible values for the parameters, otherwise Stan could try to example of assigning a negative value to <code>sigma</code>, which would generate an error when used as the standard deviation of the normal distribution in the model.</p>
</div>
<div id="vectorization" class="section level2">
<h2>Vectorization</h2>
<p>Since <code>y</code> is a vector of<code>N</code> elements, while <code>mu</code> and <code>sigma</code> each contain a single value, the instruction <code>y ~ normal (mu, sigma);</code> in the <code>model</code> block indicates that each element of <code>y</code> follows the normal distribution with parameters<code>mu</code> and <code>sigma</code>. In a linear regression model for example, <code>mu</code> would also be a vector of size <code>N</code>, so the same instruction would associate each <code>y</code> with the corresponding <code>mu</code>, while all the elements would share the same <code>sigma</code>.</p>
</div>
</div>
<div id="representating-the-model-for-the-rikz-dataset" class="section level1">
<h1>Representating the model for the <em>rikz</em> dataset</h1>
<div id="poisson-regression" class="section level2">
<h2>Poisson regression</h2>
<p>Let’s now modify the program to represent our model for the <em>rikz</em> dataset. Let’s start by describing a Poisson regression of the species richness as a function of the NAP, ignoring the effect of the exposure index and the random effect of the beach.</p>
<p>It is preferable to give the variables more descriptive names than <em>x</em>, <em>y</em> or <em>N</em>. In the <code>data</code> block, let’s change <code>N</code> for <code>n_obs</code> (number of observations) and <code>y</code> for <code>richesse</code> (<em>richness</em>), the name of our response variable.</p>
<p>For an integer variable (such as species richness), we cannot define a vector, but rather an array of <code>n_obs</code> elements, as follows: <code>int&lt;lower=0&gt; richesse[n_obs];</code>. Note that in this case, the specification of the number of elements appears after the name of the variable, as opposed to a vector where it appears after the word <code>vector</code>.</p>
<p>We also add the predictor <code>nap</code> which will be a vector of <code>n_obs</code> elements.</p>
<p>Let’s replace the contents of the <code>parameters</code> block by two parameters of our regression, <code>b0</code> (the intercept) and <code>b_nap</code> (the effect of NAP), both real.</p>
<p>In the <code>model</code> block, we first declare <code>log_lambda</code> as a vector of size <code>n_obs</code>, which will contain the log of the mean prediction for each observation. Variables declared in the <code>model</code> block are often used to define “intermediate” values which are neither model parameters nor data.</p>
<p>We can then specify the equation for the linear predictor:</p>
<pre><code>log_lambda = b0 + b_nap * nap;</code></pre>
<p>As in R, this equation is vectorized, i.e. each of the <code>n_obs</code> elements of <code>log_lambda</code> is computed from the corresponding element of <code>nap</code>, whereas <code>b0</code> and <code>b_nap</code> take only one value.</p>
<p>Finally, we replace the normal distribution for <code>y</code> with a <code>poisson</code> distribution for <code>richesse</code>. Since the only parameter of the Poisson distribution is the exponential of <code>log_lambda</code>, we could write <code>richesse ~ poisson(exp(log_lambda));</code>. However, since Poisson regression with a log link is a common model, Stan offers us a shortcut, the <code>poisson_log</code> function, which defines a Poisson distribution as a function of the log of lambda:</p>
<pre><code>richesse ~ poisson_log(log_lambda);</code></pre>
<p>Here is what our model should look like so far:</p>
<pre><code>data {
  int&lt;lower=1&gt; n_obs; // Number of observations
  int&lt;lower=0&gt; richesse[n_obs]; // Species richness
  vector[n_obs] nap;
}

parameters {
  real b0;
  real b_nap;
}

model {
  vector[n_obs] log_lambda;

  log_lambda = b0 + b_nap * nap;
  richesse ~ poisson_log(log_lambda);
} </code></pre>
<p>In the top right corner of the script window, instead of the <code>Run</code> button present for an R script, there is a <code>Check</code> button that allows us to check the syntax of the Stan model.</p>
<div id="vectorization-and-loops" class="section level3">
<h3>Vectorization and loops</h3>
<p>Integer distribution functions, such as <code>poisson_log</code>, are special because they can be vectorized (each element of <code>richesse</code> follows a distribution according to the corresponding element of <code>log_lambda</code>) even if <code>richesse</code> is not a vector as such. Not all expressions with integer numbers (type “int”) are vectorized in Stan. Without vectorization, a loop would have to be defined with the <code>for</code> instruction, as follows:</p>
<pre><code>for (i in 1:n_obs)
    richesse[i] ~ poisson_log(log_lambda[i]);</code></pre>
<p>It is a <code>for</code> loop, with a count variable <code>i</code> that will take successively the values from 1 to <code>n_obs</code>. For each value of <code>i</code>, the instructions in the loop are executed, so here <code>richesse[i]</code> follows a Poisson distribution with the parameter <code>log_lambda[i]</code>.</p>
<p>In general, the instructions in the loop (the <code>for</code> block) should be delimited by braces {}, but these can be omitted when there is only one instruction.</p>
<p>When vectorization is possible, it allows us to write a model in a more compact way and its execution will also be faster.</p>
</div>
</div>
<div id="hierarchical-model" class="section level2">
<h2>Hierarchical model</h2>
<p>We can now define the second level of the regression, which is the effect of each beach and its exposure factor on the intercept <code>b0</code>.</p>
<p>First, we need to make some changes to our data in R. In Stan, a categorical variable must be coded as integers from 1 to <span class="math inline">\(M\)</span>, where <span class="math inline">\(M\)</span> is the number of categories. This is already the case for the variable <code>Beach</code>. However, to represent the variable <code>Exposure</code> as a three-level factor, we will have to convert it first to a factor and then to an integer.</p>
<pre class="r"><code>rikz$Exp_cat &lt;- as.integer(as.factor(rikz$Exposure))
head(rikz)</code></pre>
<pre><code>##   Sample Richness Exposure    NAP Beach Exp_cat
## 1      1       11       10  0.045     1       2
## 2      2       10       10 -1.036     1       2
## 3      3       13       10 -1.336     1       2
## 4      4       11       10  0.616     1       2
## 5      5       10       10 -0.684     1       2
## 6      6        8        8  1.190     2       1</code></pre>
<p>The values 8, 10 and 11 of <code>Exposure</code> correspond to 1, 2 and 3 in the new variable <code>Exp_cat</code>.</p>
<p>Then we create a separate dataset for the beach-level data. The <code>distinct</code> function of <em>dplyr</em> keeps the unique combinations of <code>Beach</code> and <code>Exp_cat</code> present in the <code>rikz</code> dataset.</p>
<pre class="r"><code>library(dplyr)
plages &lt;- distinct(rikz, Beach, Exp_cat) %&gt;%
    arrange(Beach)
plages</code></pre>
<pre><code>##   Beach Exp_cat
## 1     1       2
## 2     2       1
## 3     3       3
## 4     4       3
## 5     5       2
## 6     6       3
## 7     7       3
## 8     8       2
## 9     9       2</code></pre>
<p>It is prudent to order this second dataset by beach number, so that the values of the variable <code>Exp_cat</code> are given to Stan in the correct order.</p>
<p>We are now ready to modify the Stan program. Under <code>data</code>, we need to declare the following variables:</p>
<ul>
<li><code>int&lt;lower=1&gt; n_plages;</code> which will denote the number of beaches (plages) present in the data set;</li>
<li><code>int&lt;lower=1, upper=n_plages&gt; plage [n_obs];</code>, a table containing for each observation the number of the corresponding beach;</li>
<li><code>int&lt;lower=1&gt; n_exp;</code>, the number of levels of the exposure index;</li>
<li><code>int&lt;lower=1, upper = n_exp&gt; exposure[n_plages];</code>, a table containing the level of the exposure index for each beach (thus the variable <code>Exp_cat</code> above).</li>
</ul>
<p>In the <code>parameters</code> block, the intercept of the model, <code>b0</code>, is now a vector of <code>n_plages</code> values, and we need to add the following parameters: <code>b0_exp</code>, a vector containing the mean intercept for each value of <code>exposure</code>, and <code>sigma_b0</code>, a real parameter with a lower bound of 0, representing the standard deviation of <code>b0</code> among beaches.</p>
<p>Finally, in the <code>model</code> block, we add the equation for the regression of <code>b0</code> for each beach, which follows a normal distribution with a mean equal to the <code>b0_exp</code> corresponding to its exposure index, and the standard deviation of <code>sigma_b0</code>.</p>
<pre><code>b0 ~ normal(b0_exp[exposure], sigma_b0);</code></pre>
<p>Note that this expression is a shortcut for the following loop:</p>
<pre><code>for (i in 1:n_plages)
    b0[i] ~ normal(b0_exp[exposure[i]], sigma_b0);</code></pre>
<p>For example, for the first beach <code>i = 1</code>, we take the value <code>exposure[1]</code>, which is equal to 2, then we take <code>b0_exp[2]</code> as the mean intercept for this beach.</p>
<p><em>Note</em>: For this model, the beach random effect <code>b0</code> is an intermediate value that we could have defined in the <code>parameters</code> or <code>model</code> block. The difference is that when the program exits, Stan will provide estimates of the posterior distribution for variables defined in <code>parameters</code>, but not those defined in <code>model</code>.</p>
<p>In the equation for <code>log_lambda</code>, the value <code>b0</code> must be replaced by the specific value for the corresponding beach:</p>
<pre><code>log_lambda = b0[plage] + b_nap * nap;
</code></pre>
<p>Once again, it is a shortcut replacing the loop:</p>
<pre><code>for (i in 1:n_obs)
    log_lambda[i] = b0[plage[i]] + b_nap * nap[i];</code></pre>
</div>
<div id="prior-distributions" class="section level2">
<h2>Prior distributions</h2>
<p>This model contains three parameters currently without a distribution: <code>b_nap</code>, <code>b0_exp</code> (a vector of three values) and <code>sigma_b0</code>. If we do not specify prior distributions for these parameters, Stan chooses extremely diffuse prior distributions within the specified bounds, which produce estimates equivalent to the maximum likelihood. This works if we have a lot of data, but as we have seen in the course, it is recommended in the Bayesian approach to choose prior distributions that establish weak constraints on the value of our parameters.</p>
<p>We will use the same prior distributions as the example using <em>brms</em> in the course notes:</p>
<pre><code>b_nap ~ normal(0, 1);
b0_exp ~ normal(2, 1);
sigma_b0 ~ normal(0, 0.5);</code></pre>
<p>Note that the three values of <code>b0_exp</code> have the same prior distribution as the original intercept in the course notes. Using <em>brms</em>, the model is parameterized differently for the categorical predictor <code>exposure</code> (with contrasts, as in R). Here we fit an intercept for each <code>exposure</code> value, rather than an intercept for the reference level and contrasts for the differences between that reference level and the other two levels.</p>
<p><em>Note</em>: Here, the response (on the log scale) and the sole numerical predictor (NAP) take values on a scale of a few units. If the numerical variables in the problem have orders of magnitude very different from each other, it may be useful to standardize them, for example with `scale’ in R, because the Bayesian inference algorithm works best if all variables have comparable scales, rather than having very large and very small values.</p>
<p>Here is the program obtained so far:</p>
<pre><code>data {
  int&lt;lower=1&gt; n_obs; // Number of observations
  int&lt;lower=1&gt; n_plages; // Number of beaches
  int&lt;lower=0&gt; richesse[n_obs]; // Species richness
  vector[n_obs] nap;
  int&lt;lower=1, upper=n_plages&gt; plage[n_obs]; // Beach corresponding to each observation
  int&lt;lower=1&gt; n_exp; // Number of values of the exposure index
  int&lt;lower=1, upper = n_exp&gt; exposure[n_plages];
}

parameters {
  vector[n_plages] b0;
  real b_nap;
  vector[n_exp] b0_exp; // Mean intercept for each level of exposure
  real&lt;lower=0&gt; sigma_b0; // Standard deviation of the intercept
}

model {
  vector[n_obs] log_lambda;
  
  b_nap ~ normal(0, 1);
  b0_exp ~ normal(2, 1);
  sigma_b0 ~ normal(0, 0.5);
  
  b0 ~ normal(b0_exp[exposure], sigma_b0);
  log_lambda = b0[plage] + b_nap * nap;
  richesse ~ poisson_log(log_lambda);
}  </code></pre>
</div>
</div>
<div id="fitting-the-model-in-r" class="section level1">
<h1>Fitting the model in R</h1>
<p>To fit a model written in Stan, we use the <em>rstan</em> package.</p>
<pre class="r"><code>library(rstan)</code></pre>
<p>First, we create a data list that will contain each variable included in the <code>data</code> block of the model. It is important that the name of the element in the list (before each <code>=</code>) is the same as the name of the variable in the Stan code. For example, here we get <code>n_obs</code> from the number of rows in the <code>rikz</code> dataset, <code>richesse</code> from the <code>rikz$Richness</code> column, etc.</p>
<pre class="r"><code>rikz_dat &lt;- list(
    n_obs = nrow(rikz),
    n_plages = nrow(plages),
    richesse = rikz$Richness,
    nap = rikz$NAP,
    plage = rikz$Beach,
    n_exp = max(plages$Exp_cat),
    exposure = plages$Exp_cat
)</code></pre>
<p>Then, fitting the model using the Monte Carlo algorithm is done in two steps. First, we compile the Stan program into a <code>rikz_mod</code> object with <code>stan_model</code>, then we fit this model with our <code>rikz_dat</code> data with <code>sampling</code>. We specify a number of chains (2) smaller than the default value of 4, but we keep the other default values (2000 iterations, including 1000 warmup).</p>
<p>The <code>sampling</code> function displays its progress for each chain. Here, after the compilation which takes a few minutes, the fit itself is done very quickly.</p>
<pre class="r"><code>rikz_mod &lt;- stan_model(&quot;rikz.stan&quot;)
rikz_res &lt;- sampling(rikz_mod, data = rikz_dat, chains = 2)</code></pre>
<pre><code>## 
## SAMPLING FOR MODEL &#39;rikz&#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 0 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.152 seconds (Warm-up)
## Chain 1:                0.122 seconds (Sampling)
## Chain 1:                0.274 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &#39;rikz&#39; NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 0 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.158 seconds (Warm-up)
## Chain 2:                0.281 seconds (Sampling)
## Chain 2:                0.439 seconds (Total)
## Chain 2:</code></pre>
<pre><code>## Warning: There were 20 divergent transitions after warmup. See
## http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup
## to find out why this is a problem and how to eliminate them.</code></pre>
<pre><code>## Warning: Examine the pairs() plot to diagnose sampling problems</code></pre>
<p>Here, Stan warns us that there are several divergent transitions in the sampling period, so the validity of the inferences could be compromised. To diagnose this problem, it may be useful to launch the interactive application ShinyStan, from the package of the same name. Note that the ShinyStan application is also compatible with the output of a model fitted with <em>brms</em>.</p>
<pre class="r"><code>library(shinystan)
launch_shinystan(rikz_res)</code></pre>
<p>For now, we are focusing on the <em>Diagnose</em> tab of the application. You can see the distribution of a variable for each iteration and the values corresponding to the divergent iterations are given by red points. In particular, if you choose the variable <code>sigma_b0</code>, you will see that divergences occur for small values of <code>sigma_b0</code>.</p>
<div id="non-centered-parameterization" class="section level2">
<h2>Non-centered parameterization</h2>
<p>In the model above, we asked Stan to estimate both the random effects <code>b0</code> of each beach, as well as their standard deviation <code>sigma_b0</code>. At the level of the algorithm, the dependence between these quantities can be problematic. Briefly, this is due to the fact that when the standard deviation <code>sigma_b0</code> is very small, even very small deviations of <code>b0</code> around their mean value become unlikely; thus the likelihood gradients are very steep and the Markov chain cannot progress normally.</p>
<p>It is therefore recommended to use a so-called “non-centered” parameterization for random effects in Stan. In other words, if the intercept of a group <span class="math inline">\(j\)</span> is drawn from a normal distribution with a mean <span class="math inline">\(\mu_{\beta_0}\)</span> and a standard deviation <span class="math inline">\(\sigma_{\beta_0}\)</span>:</p>
<p><span class="math display">\[\beta_{0j} \sim \text{N}(\mu_{\beta_0}, \sigma_{\beta_0})\]</span></p>
<p>we can represent the same model as follows:</p>
<p><span class="math display">\[\beta_{0j} = \mu_{\beta_0} + \sigma_{\beta_0} \nu_j\]</span></p>
<p>where <span class="math inline">\(\nu_j \sim \text{N}(0, 1)\)</span> is a standard normal random variable. Since the random effects <span class="math inline">\(\nu_j\)</span> are represented in multiples of <span class="math inline">\(\sigma_{\beta_0}\)</span>, these two parameters are therefore decoupled.</p>
<p>In the code below, we used the variable <code>b0_alea</code> for <span class="math inline">\(\nu_j\)</span>. Since <code>b0</code> is now a value that depends entirely on a combination of other parameters and data, we can define it in a new <code>transformed parameters</code> block. The distribution of the variables in this block, like those in <code>parameters</code>, will be given by Stan at the output of the program.</p>
<pre><code>data {
  int&lt;lower=1&gt; n_obs; // Number of observations
  int&lt;lower=1&gt; n_plages; // Number of beaches
  int&lt;lower=0&gt; richesse[n_obs]; // Species richness
  vector[n_obs] nap;
  int&lt;lower=1, upper=n_plages&gt; plage[n_obs]; // Beach corresponding to each observation
  int&lt;lower=1&gt; n_exp; // Number of levels of the exposure index
  int&lt;lower=1, upper = n_exp&gt; exposure[n_plages];
}

parameters {
  vector[n_plages] b0_alea; // Standardized random effect on the intercept
  real b_nap;
  vector[n_exp] b0_exp; // Mean intercept for each exposure level
  real&lt;lower=0&gt; sigma_b0; // Standard deviation of the intercept
}

transformed parameters {
  vector[n_plages] b0;
  b0 = b0_exp[exposure] + sigma_b0 * b0_alea;
}

model {
  vector[n_obs] log_lambda;
  
  b_nap ~ normal(0, 1);
  b0_exp ~ normal(2, 1);
  sigma_b0 ~ normal(0, 0.5);
  b0_alea ~ normal(0, 1);
  
  log_lambda = b0[plage] + b_nap * nap;
  richesse ~ poisson_log(log_lambda);
}  </code></pre>
<p>When fitting this new version of the model, divergences are eliminated or at least reduced. (In this particular example where the posterior distribution of <code>sigma_b0</code> is approaching 0, it may be necessary to increase <code>adapt_delta</code>, as seen in the example in the course notes, to completely eliminate the divergences.)</p>
<pre class="r"><code># new version of the model in the file &quot;rikz2.stan&quot;
rikz_mod2 &lt;- stan_model(&quot;rikz2.stan&quot;)
rikz_res2 &lt;- sampling(rikz_mod2, data = rikz_dat, chains = 2)</code></pre>
<pre><code>## 
## SAMPLING FOR MODEL &#39;rikz2&#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 0 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.211 seconds (Warm-up)
## Chain 1:                0.181 seconds (Sampling)
## Chain 1:                0.392 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &#39;rikz2&#39; NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 0 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.226 seconds (Warm-up)
## Chain 2:                0.217 seconds (Sampling)
## Chain 2:                0.443 seconds (Total)
## Chain 2:</code></pre>
</div>
<div id="exploring-the-results" class="section level2">
<h2>Exploring the results</h2>
<p>The result produced by <code>sampling</code> is a <code>stanfit</code> type object. Here are some of the functions that apply to these objects.</p>
<p>The <code>check_hmc_diagnostics</code> function checks the three diagnostics of the Hamiltonian Monte Carlo method.</p>
<pre class="r"><code>check_hmc_diagnostics(rikz_res2)</code></pre>
<pre><code>## 
## Divergences:</code></pre>
<pre><code>## 0 of 2000 iterations ended with a divergence.</code></pre>
<pre><code>## 
## Tree depth:</code></pre>
<pre><code>## 0 of 2000 iterations saturated the maximum tree depth of 10.</code></pre>
<pre><code>## 
## Energy:</code></pre>
<pre><code>## E-BFMI indicated no pathological behavior.</code></pre>
<p>The <code>show</code> function shows a summary of the posterior distribution of each parameter.</p>
<pre class="r"><code>show(rikz_res2)</code></pre>
<pre><code>## Inference for Stan model: rikz2.
## 2 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=2000.
## 
##              mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
## b0_alea[1]   0.53    0.02 0.77  -0.99   0.05   0.54   1.00   2.11  1309    1
## b0_alea[2]   0.09    0.03 0.97  -1.78  -0.54   0.07   0.72   1.98  1421    1
## b0_alea[3]  -0.16    0.02 0.81  -1.78  -0.70  -0.16   0.36   1.45  1601    1
## b0_alea[4]  -0.30    0.02 0.83  -1.90  -0.85  -0.32   0.28   1.38  1810    1
## b0_alea[5]   0.77    0.02 0.78  -0.77   0.25   0.76   1.29   2.33  1432    1
## b0_alea[6]   0.26    0.02 0.82  -1.37  -0.25   0.25   0.80   1.90  1624    1
## b0_alea[7]  -0.11    0.02 0.84  -1.77  -0.69  -0.12   0.47   1.60  2172    1
## b0_alea[8]  -0.91    0.02 0.81  -2.51  -1.45  -0.92  -0.36   0.60  1568    1
## b0_alea[9]  -0.42    0.02 0.78  -1.91  -0.94  -0.45   0.06   1.17  1576    1
## b_nap       -0.50    0.00 0.07  -0.64  -0.55  -0.50  -0.45  -0.36  1619    1
## b0_exp[1]    2.48    0.01 0.27   1.88   2.33   2.49   2.64   3.03  1132    1
## b0_exp[2]    1.91    0.00 0.15   1.60   1.82   1.92   2.00   2.19   931    1
## b0_exp[3]    1.21    0.01 0.18   0.88   1.09   1.20   1.32   1.59   835    1
## sigma_b0     0.22    0.01 0.13   0.02   0.13   0.21   0.30   0.53   487    1
## b0[1]        2.03    0.00 0.13   1.79   1.94   2.02   2.11   2.28  1738    1
## b0[2]        2.51    0.00 0.13   2.25   2.42   2.51   2.60   2.75  2275    1
## b0[3]        1.17    0.00 0.18   0.80   1.05   1.17   1.29   1.52  3183    1
## b0[4]        1.13    0.00 0.20   0.72   1.01   1.14   1.26   1.50  2035    1
## b0[5]        2.08    0.00 0.15   1.80   1.97   2.08   2.18   2.38  1397    1
## b0[6]        1.27    0.00 0.19   0.91   1.14   1.26   1.39   1.64  2389    1
## b0[7]        1.18    0.00 0.20   0.73   1.06   1.19   1.31   1.57  2972    1
## b0[8]        1.70    0.01 0.19   1.29   1.58   1.72   1.84   2.03   982    1
## b0[9]        1.81    0.00 0.17   1.44   1.72   1.83   1.93   2.11  1933    1
## lp__       243.83    0.18 3.15 236.95 241.97 244.12 246.12 248.95   296    1
## 
## Samples were drawn using NUTS(diag_e) at Tue Feb 09 05:49:36 2021.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
<p>The <code>extract</code> function extracts all samples from the posterior distribution of the parameters.</p>
<pre class="r"><code>rikz_pars &lt;- extract(rikz_res2)
str(rikz_pars)</code></pre>
<pre><code>## List of 6
##  $ b0_alea : num [1:2000, 1:9] 1.028 -1.174 1.093 -0.085 1.244 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. ..$ iterations: NULL
##   .. ..$           : NULL
##  $ b_nap   : num [1:2000(1d)] -0.468 -0.585 -0.374 -0.406 -0.498 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 1
##   .. ..$ iterations: NULL
##  $ b0_exp  : num [1:2000, 1:3] 2.68 2.66 2.5 2.36 2.33 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. ..$ iterations: NULL
##   .. ..$           : NULL
##  $ sigma_b0: num [1:2000(1d)] 0.00242 0.18054 0.16915 0.09995 0.1935 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 1
##   .. ..$ iterations: NULL
##  $ b0      : num [1:2000, 1:9] 2.1 1.87 2.2 1.97 2 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. ..$ iterations: NULL
##   .. ..$           : NULL
##  $ lp__    : num [1:2000(1d)] 236 240 243 245 245 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 1
##   .. ..$ iterations: NULL</code></pre>
<p>The <code>plot</code> function, by default, shows a graph of the estimates for the parameters given by the <code>pars</code> argument, with their credibility interval at 80% (bold line) and 95% (thinner line).</p>
<pre class="r"><code>plot(rikz_res2, pars = c(&quot;b0&quot;, &quot;b_nap&quot;))</code></pre>
<pre><code>## ci_level: 0.8 (80% intervals)</code></pre>
<pre><code>## outer_level: 0.95 (95% intervals)</code></pre>
<p><img src="09E-Modeles_hierarchiques_bayesiens_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Other graphs can be produced by varying the <code>plotfun</code> argument, such as trace plots for the two Monte Carlo chains, or histograms of the posterior distribution of the parameters.</p>
<pre class="r"><code>plot(rikz_res2, pars = c(&quot;b_nap&quot;, &quot;b0_exp&quot;, &quot;sigma_b0&quot;), 
     plotfun = &quot;trace&quot;)</code></pre>
<p><img src="09E-Modeles_hierarchiques_bayesiens_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<pre class="r"><code>plot(rikz_res2, pars = c(&quot;b_nap&quot;, &quot;b0_exp&quot;, &quot;sigma_b0&quot;), 
     plotfun = &quot;hist&quot;)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="09E-Modeles_hierarchiques_bayesiens_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>As seen earlier, <code>launch_shinystan</code> launches an interactive application to view model diagnostics, summaries and graphs of the posterior distribution of parameters, as well as other aspects of the fitted model.</p>
</div>
</div>
<div id="using-the-brms-package" class="section level1">
<h1>Using the <em>brms</em> package</h1>
<p>The <em>brms</em> package allows us to implement several models without writing the Stan code ourselves. It is recommended to use it whenever possible, because <em>brms</em> automatically takes care of optimizing the Stan code, for example standardizing the predictors, adopting a non-centered parameterization, etc.</p>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<p>Documentation for Stan: <a href="https://mc-stan.org/users/documentation/">https://mc-stan.org/users/documentation/</a></p>
<p>Introduction to Stan by Michael Betancourt: <a href="https://betanalpha.github.io/assets/case_studies/stan_intro.html">https://betanalpha.github.io/assets/case_studies/stan_intro.html</a></p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
