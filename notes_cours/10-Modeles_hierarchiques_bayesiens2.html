<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Modèles hiérarchiques bayésiens 2</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/spacelab.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>
<link href="libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Modèles hiérarchiques bayésiens 2</h1>

</div>


<div id="contenu-du-cours" class="section level1">
<h1>Contenu du cours</h1>
<ul>
<li><p>Révision: Comparaison et sélection de modèles</p></li>
<li><p>Approche bayésienne pour la comparaison de modèles</p></li>
<li><p>Comparaison de modèles avec <em>loo</em> et <em>brms</em></p></li>
<li><p>Plus d’exemples de modèles bayésiens en écologie</p></li>
</ul>
</div>
<div id="comparaison-et-sélection-de-modèles" class="section level1">
<h1>Comparaison et sélection de modèles</h1>
<p>Supposons que nous avons différents modèles statistiques qui visent à expliquer les mêmes données. Les modèles pourraient inclure différents prédicteurs, une distribution différente de la réponse, etc. Comment déterminer quel modèle représente le mieux le phénomène étudié?</p>
<p>La plupart des méthodes de comparaison de modèles cherchent à optimiser la capacité du modèle à <strong>prédire de nouvelles observations</strong> du phénomène. Autrement dit, il ne suffit pas d’évaluer si le modèle s’approche des données utilisées pour son ajustement. Un modèle plus complexe, avec davantage de paramètres ajustables, va toujours être plus près de ces données.</p>
<p>De façon générale, un modèle trop simple comporte une grande erreur systématique (biais ou sous-ajustement), car il omet des effets importants sur la variable réponse; un modèle trop complexe comporte une grande erreur aléatoire (variance ou surajustement), car il tend à représenter des associations “accidentelles” d’un échantillon particulier qui ne se généralisent pas à la population. Le compromis idéal entre ces deux types d’erreur, qui minimise l’erreur totale, dépend de la quantité de données, car un grand échantillon diminue la variance associée à l’estimation de nombreux paramètres dans un modèle complexe.</p>
<p><img src="../images/biais_variance.png" /></p>
<p>Avec des grands jeux de données, il est possible de mettre de côté une partie des données (souvent ~20 à 30%) pour créer un ensemble de validation, tandis que le reste des données forment l’ensemble d’entraînement (<em>training set</em>). Dans ce cas, chacun des modèles candidats est ajusté à partir des données d’entraînement et la performance prédictive des modèles ajustés est évaluée sur l’ensemble de validation.</p>
<div id="validation-croisée" class="section level2">
<h2>Validation croisée</h2>
<p>La mise de côté d’une partie des données pour la validation n’est pas pratique si la taille de l’échantillon est modeste. Avec relativement peu de données, chaque point est important pour estimer précisément les paramètres du modèle; aussi, plus l’ensemble de validation est petit, plus il a des chances d’être non-représentatif de la population.</p>
<p>La validation croisée (<em>cross-validation</em>) offre une façon d’évaluer la performance prédictive sur des nouvelles observations sans avoir à mettre de côté un ensemble de validation. Cette méthode consiste à diviser aléatoirement les observations en groupes et mesurer la qualité de la prédiction des observations d’un groupe selon un modèle ajusté au reste des observations.</p>
<p>Par exemple, si chaque groupe ne comporte qu’une seule observation (<em>leave-one-out cross-validation</em>), nous pouvons évaluer la prédiction de chaque valeur de la réponse <span class="math inline">\(y_i\)</span> pour un modèle ajusté sans l’observation <span class="math inline">\(i\)</span>. Cependant, cette méthode requiert de réajuster le modèle <span class="math inline">\(n\)</span> fois, où <span class="math inline">\(n\)</span> est le nombre d’observations.</p>
<p>Si le nombre d’observations est grand, il peut être plus pratique de diviser les observations en <span class="math inline">\(k\)</span> groupes (<em>k-fold cross-validation</em>), par exemple <span class="math inline">\(k\)</span> = 10, et d’ajuster chaque modèle à évaluer <span class="math inline">\(k\)</span> fois en laissant une fraction <span class="math inline">\(1/k\)</span> des observations de côté.</p>
</div>
<div id="critère-dinformation-dakaike" class="section level2">
<h2>Critère d’information d’Akaike</h2>
<p>Puisque les méthodes de validation croisée sont coûteuses en terme de calcul, il est utile de pouvoir approximer l’erreur de prédiction qui serait obtenue en validation croisée sans avoir à réajuster le modèle plusieurs fois.</p>
<p>Pour les modèles ajustés par la méthode du maximum de vraisemblance, le critère d’information d’Akaike (AIC) offre une mesure d’ajustement basée sur la théorie de l’information, qui tend à produire le même résultat que la validation croisée <em>leave-one-out</em> si la taille de l’échantillon est assez grand. L’AIC est calculé ainsi:</p>
<p><span class="math display">\[ AIC = -2 \log L + 2 K \]</span></p>
<p>où <span class="math inline">\(L\)</span> est la fonction de vraisemblance à son maximum et <span class="math inline">\(K\)</span> est le nombre de paramètres estimés par le modèle. Une petite valeur de l’AIC représente un meilleur pouvoir prédictif du modèle. Le premier terme de l’équation représente l’ajustement aux données observées, tandis que le deuxième terme pénalise les modèles plus complexes.</p>
<p>L’AIC est défini à une constante additive près, donc sa valeur absolue ne donne aucune information. C’est plutôt la différence d’AIC entre les modèles candidats qui est interprétable. Cette différence est définie par rapport à la valeur minimale de l’AIC parmi les modèles comparés: <span class="math inline">\(\Delta AIC = AIC - \min AIC\)</span>. Le meilleur modèle a un <span class="math inline">\(\Delta AIC = 0\)</span>.</p>
<p>L’expression:</p>
<p><span class="math display">\[ e^{-\frac{\Delta AIC}{2} } \]</span></p>
<p>correspond au rapport de la plausibilité (<em>evidence ratio</em>) de chaque modèle vs. celui ayant l’AIC minimal. Par exemple, <span class="math inline">\(\Delta AIC = 2\)</span> correspond à un ratio de ~0.37 (~3 fois moins probable), tandis que <span class="math inline">\(\Delta AIC = 10\)</span> correspond à un ratio de ~0.0067 (~150 fois moins probable).</p>
</div>
<div id="prédictions-multi-modèles" class="section level2">
<h2>Prédictions multi-modèles</h2>
<p>Avec <span class="math inline">\(m\)</span> modèles candidats, on peut se servir des rapports de plausibilité décrits ci-dessus pour définir le poids d’Akaike <span class="math inline">\(w\)</span> pour chaque modèle:</p>
<p><span class="math display">\[w_i = \frac{e^{\frac{-\Delta AIC_i}{2}}}{\sum_{j=1}^{m} e^{\frac{-\Delta AIC_j}{2}}}\]</span></p>
<p>Le dénominateur normalise chaque rapport par leur somme, de façon à ce que la somme des poids <span class="math inline">\(w_i\)</span> égale 1.</p>
<p>Si plusieurs modèles sont plausibles et ont un poids d’Akaike non-négligeable, alors il est possible de faire la moyenne de leurs prédictions d’une nouvelle observation de la réponse (cette prédiction est notée <span class="math inline">\(\tilde{y}\)</span>), en pondérant la prédiction <span class="math inline">\(\tilde{y_j}\)</span> de chaque modèle candidat par son poids <span class="math inline">\(w_j\)</span>.</p>
<p><span class="math display">\[\tilde{y} = \sum_{j = 1}^m w_j \tilde{y_j}\]</span></p>
<p>Les prédictions multi-modèles sont souvent plus précises que celles obtenues en considérant seulement le meilleur modèle, car elles tiennent compte de l’incertitude sur la forme du modèle.</p>
</div>
</div>
<div id="approche-bayésienne-pour-la-comparaison-de-modèles" class="section level1">
<h1>Approche bayésienne pour la comparaison de modèles</h1>
<div id="densité-prédictive" class="section level2">
<h2>Densité prédictive</h2>
<p>Pour un modèle estimé par maximum de vraisemblance, les prédictions de nouvelles observations sont obtenues en fixant les paramètres du modèles à leur valeur estimée. La vraisemblance de cette nouvelle observation est donc <span class="math inline">\(p(\tilde{y} | \hat{\theta})\)</span>, où <span class="math inline">\(\hat{\theta}\)</span> sont les estimés des paramètres au maximum de vraisemblance.</p>
<p>Dans une approche bayésienne, les prédictions de nouvelles observations sont obtenues en faisant la moyenne des prédictions en fonction de la distribution <em>a posteriori</em> de la valeur des paramètres. La densité prédictive de <span class="math inline">\(\tilde{y}\)</span> en fonction du modèle ajusté aux observations <span class="math inline">\(y\)</span>, notée <span class="math inline">\(p(\tilde{y} | y)\)</span>, est égale à la moyenne de la vraisemblance <span class="math inline">\(p(\tilde{y} | \theta)\)</span> pour la distribution <em>a posteriori</em> conjointe des <span class="math inline">\(\theta\)</span>:</p>
<p><span class="math inline">\(p(\tilde{y} | y) = \int p(\tilde{y} | \theta) p(\theta | y) \text{d}\theta\)</span> .</p>
<p>En pratique, si un algorithme de Monte-Carlo génère <span class="math inline">\(S\)</span> vecteurs de paramètres <span class="math inline">\(\theta_{(1)}, ..., \theta_{(S)}\)</span> approximant la distribution <em>a posteriori</em>, nous calculons <span class="math inline">\(p(\tilde{y} | y)\)</span> par la moyenne des prédictions de chaque vecteur:</p>
<p><span class="math inline">\(p(\tilde{y} | y) = \frac{1}{S} \sum_{j = 1}^S p(\tilde{y} | \theta_{(j)})\)</span> .</p>
<p>Comme pour la vraisemblance, il est plus facile de travailler avec le logarithme de la densité prédictive.</p>
</div>
<div id="validation-croisée-1" class="section level2">
<h2>Validation croisée</h2>
<p>Pour déterminer le modèle qui maximise la densité prédictive de nouvelles observations, telle que définie ci-dessus, nous pouvons utiliser la validation croisée. Cependant, puisque l’ajustement des modèles hiérarchiques bayésiens demande parfois considérablement de temps de calcul, il n’est pas pratique dans ces cas de répéter l’estimation du modèle un grand nombre de fois, en laissant de côté une partie des données. Nous utilisons donc le plus souvent des critères qui approximent la performance prédictive d’une validation croisée.</p>
<p>Si l’AIC approxime bien l’erreur de validation croisée pour les modèles ajustés par maximum de vraisemblance avec un nombre d’observations assez grand, ce critère s’applique mal aux modèles bayésiens. D’une part, le maximum de vraisemblance n’est pas directement produit par l’ajustement du modèle bayésien. De plus, il est difficile de définir un nombre de paramètres ajustables <span class="math inline">\(K\)</span> en raison de la structure hiérarchique et des contraintes imposées par les distributions <em>a priori</em> des paramètres, qui font que ces paramètres ne varient pas librement.</p>
</div>
<div id="critères-de-sélection-pour-les-modèles-hiérarchiques-bayésiens" class="section level2">
<h2>Critères de sélection pour les modèles hiérarchiques bayésiens</h2>
<div id="dic" class="section level3">
<h3>DIC</h3>
<p>Le critère d’information de la déviance (DIC), basé sur l’AIC, a été l’un des premiers critères développés pour la comparaison de modèles bayésiens:</p>
<p><span class="math display">\[DIC = -2 \log p(y | \bar{\theta}) + 2 p_D\]</span></p>
<p>où <span class="math inline">\(\bar{\theta}\)</span> est la moyenne de la distribution <em>a posteriori</em> de <span class="math inline">\(\theta\)</span> et <span class="math inline">\(p_D\)</span> est le nombre effectif de paramètres, qui peut être calculé de plusieurs façons.</p>
<p>Comme l’AIC, le DIC représente bien la performance prédictive relative de modèles sur de nouvelles données, si la taille de l’échantillon est assez grand. Cependant, il ne s’agit pas d’une prédiction bayésienne car elle se base sur un estimé unique de chaque paramètre (sa valeur moyenne) plutôt que sur la distribution <em>a posteriori</em> au complet.</p>
</div>
<div id="waic" class="section level3">
<h3>WAIC</h3>
<p>Le critère de Watanabe-Akaike (WAIC) est semblable au DIC, mais le premier terme est basé sur la densité prédictive conjointe des observations <span class="math inline">\(y_1, ..., y_n\)</span>.</p>
<p><span class="math display">\[WAIC = -2 \sum_{i=1}^n \log \left( \frac{1}{S} \sum_{j = 1}^S p(y_i | \theta_{(j)}) \right) + 2 p_W\]</span> ,</p>
<p>où la pénalité <span class="math inline">\(p_W\)</span> est la somme des variances du logarithme de la densité prédictive à chaque point:</p>
<p><span class="math display">\[p_W = \sum_{i=1}^n \text{Var}_j \left(\log p(y_i | \theta_{(j)}) \right)\]</span></p>
<p>Ici, Var<span class="math inline">\(_j\)</span> désigne la variance de l’expression entre parenthèses sur l’ensemble des itérations <span class="math inline">\(j\)</span>.</p>
<p>Le WAIC d’un modèle <em>brms</em> peut être calculé avec la fonction <code>waic</code>.</p>
</div>
<div id="psis-loo" class="section level3">
<h3>PSIS-LOO</h3>
<p>Une méthode développée récemment par Vehtari et al. (2017) consiste à estimer la densité prédictive à chaque point qui serait obtenue par validation croisée <em>leave-one-out</em>, c’est-à-dire en prédisant <span class="math inline">\(y_i\)</span> à partir du modèle ajusté aux données excluant <span class="math inline">\(i\)</span>, <span class="math inline">\(y_{-i}\)</span>.</p>
<p><span class="math inline">\(p(y_i | y_{-i}) = \int p(y_i | \theta) p(\theta | y_{-i}) \text{d}\theta\)</span> .</p>
<p>La méthode PSIS-LOO (PSIS = <em>Patero smoothed importance sampling</em>, LOO = <em>leave-one-out</em>) vise à estimer cette quantité sans effectuer la validation croisée. En bref, cette approximation est obtenue en faisant la moyenne des <span class="math inline">\(p(y | \theta_{(j)})\)</span>, mais avec une pondération particulière des <span class="math inline">\(\theta_{(j)}\)</span> (échantillonnage préférentiel). Cette pondération est ensuite ajustée pour que les poids extrêmes suivent un modèle théorique (distribution de Pareto).</p>
<p>Cette méthode est implémentée dans le package R <em>loo</em> et peut être appelée à partir de la fonction <code>loo</code> appliquée au résultat d’un modèle dans <em>brms</em>.</p>
<p>Comme nous verrons dans l’exemple plus loin, la méthode PSIS-LOO produit son propre diagnostic. L’ajustement des poids pour chaque valeur <span class="math inline">\(y_i\)</span> est basé sur un paramètre de la distribution de Pareto <span class="math inline">\(k\)</span> et lorsque <span class="math inline">\(k &gt; 0.7\)</span>, l’approximation de <span class="math inline">\(p(y_i | y_{-i})\)</span> est potentiellement instable. Si ce problème se produit pour quelques observations, il est possible de réajuster le modèle en excluant ces observations seulement afin de calculer directement <span class="math inline">\(p(y_i | y_{-i})\)</span>.</p>
<p>Le résultat de cette méthode est l’estimé du logarithme de la densité prédictive <span class="math inline">\(elpd_{loo}\)</span>, autrement dit la somme de <span class="math inline">\(\log p(y_i | y_{-i})\)</span>. Un critère d’information (LOOIC) semblable au DIC et WAIC peut être obtenu en multipliant <span class="math inline">\(elpd_{loo}\)</span> par -2.</p>
</div>
<div id="comparaison-des-méthodes" class="section level3">
<h3>Comparaison des méthodes</h3>
<p>La méthode PSIS-LOO est un peu plus précise que le WAIC, surtout pour les petits échantillons, mais le WAIC est généralement plus rapide à calculer.</p>
<p>Puisqu’elles sont basés sur la densité prédictive bayésienne plutôt que sur un seul estimé moyen de chaque paramètre, ces deux méthodes (WAIC et PSIS-LOO) sont actuellement préférées au DIC. Cependant, les deux supposent que les observations individuelles <span class="math inline">\(y_i\)</span> soient indépendantes les unes des autres, conditionnellement à la valeur des paramètres. Typiquement, cette supposition n’est pas respectée si le modèle inclut directement une corrélation entre différentes valeurs de la réponse (ex.: corrélation temporelle ou spatiale).</p>
</div>
</div>
<div id="prédictions-multi-modèles-1" class="section level2">
<h2>Prédictions multi-modèles</h2>
<p>Dans la section précédente, nous avons vu qu’une prédiction multi-modèles pour une nouvelle observation <span class="math inline">\(\tilde{y}\)</span> est calculée par la moyenne pondérée des prédictions des différents modèles.</p>
<p><span class="math display">\[\tilde{y} = \sum_{j = 1}^m w_j \tilde{y_j}\]</span></p>
<p>Comme pour l’AIC, nous pouvons définir des poids selon les différences d’IC entre deux modèles et cela pour différents critères bayésiens (ex.: WAIC, LOOIC).</p>
<p>Cependant, il n’est pas toujours optimal de combiner les modèles proportionnellement à leur plausibilité. Par exemple, les deux meilleurs modèles peuvent produire des prédictions redondantes, tandis que le troisième et quatrième meilleur modèle peuvent aider à corriger certaines prédictions moins bonnes du meilleur modèle.</p>
<p>La <strong>superposition de modèles</strong> (<em>model stacking</em>) consiste à chercher les poids <span class="math inline">\(w_j\)</span> qui minimisent l’erreur de prédiction multi-modèles donnée par la moyenne pondérée (Yao et al. 2018). Ce calcul peut être fait directement à partir des résultats de la méthode PSIS-LOO, comme nous verrons dans l’exemple de la prochaine section.</p>
</div>
</div>
<div id="comparaison-de-modèles-avec-loo-et-brms" class="section level1">
<h1>Comparaison de modèles avec <em>loo</em> et <em>brms</em></h1>
<p>Le jeu de données <a href="../donnees/rikz.csv">rikz.csv</a> contient des données sur la richesse de la microfaune benthique (<em>Richness</em>) pour 45 sites répartis sur 5 plages (<em>Beach</em>) aux Pays-Bas, en fonction de la position verticale du site (<em>NAP</em>) et d’un indice d’exposition mesuré au niveau de la plage (<em>Exposure</em>).</p>
<pre class="r"><code>rikz &lt;- read.csv(&quot;../donnees/rikz.csv&quot;)
rikz$Exposure &lt;- as.factor(rikz$Exposure)
head(rikz)</code></pre>
<pre><code>##   Sample Richness Exposure    NAP Beach
## 1      1       11       10  0.045     1
## 2      2       10       10 -1.036     1
## 3      3       13       10 -1.336     1
## 4      4       11       10  0.616     1
## 5      5       10       10 -0.684     1
## 6      6        8        8  1.190     2</code></pre>
<p>La semaine dernière, nous avions ajusté avec <em>brms</em> un modèle de régression de Poisson pour la richesse spécifique en fonction de <em>NAP</em> et <em>Exposure</em>, avec un effet aléatoire de la plage sur l’ordonnée à l’origine.</p>
<pre class="r"><code>library(brms)

rikz_prior &lt;- c(set_prior(&quot;normal(0, 1)&quot;, class = &quot;b&quot;),
                set_prior(&quot;normal(2, 1)&quot;, class = &quot;Intercept&quot;),
                set_prior(&quot;normal(0, 0.5)&quot;, class = &quot;sd&quot;))

mod1 &lt;- brm(Richness ~ NAP + Exposure + (1 | Beach), data = rikz, 
            family = poisson, prior = rikz_prior,
            control = list(adapt_delta = 0.99))</code></pre>
<p>Nous considérons maintenant une autre version du modèle où l’effet du <em>NAP</em> varie aussi aléatoirement d’une plage à l’autre.</p>
<pre class="r"><code>mod2 &lt;- brm(Richness ~ NAP + Exposure + (1 + NAP | Beach), data = rikz, 
            family = poisson, prior = rikz_prior,
            control = list(adapt_delta = 0.99))</code></pre>
<p>Voici les effets fixes et l’écart-type des effets aléatoires estimés pour les deux modèles. Dans le modèle 2, l’incertitude sur <code>b_NAP</code> a augmenté et l’effet aléatoire de la plage sur ce coefficient a un écart-type de 0.34 avec un intervalle de crédibilité de 0.06 à 0.70, comparable à l’effet aléatoire de la plage sur l’ordonnée à l’origine.</p>
<pre class="r"><code>posterior_summary(mod1, pars = &quot;b|sd&quot;)</code></pre>
<pre><code>##                       Estimate  Est.Error        Q2.5      Q97.5
## b_Intercept          2.3768063 0.29928962  1.65052195  2.9026726
## b_NAP               -0.5022979 0.07147339 -0.64245708 -0.3635854
## b_Exposure10        -0.4591405 0.32879974 -1.04058741  0.2932071
## b_Exposure11        -1.1593086 0.34394732 -1.76553502 -0.3930065
## sd_Beach__Intercept  0.2474170 0.13614456  0.02605894  0.5622590</code></pre>
<pre class="r"><code>posterior_summary(mod2, pars = &quot;b|sd&quot;)</code></pre>
<pre><code>##                       Estimate Est.Error        Q2.5      Q97.5
## b_Intercept          2.3730140 0.3342694  1.59135757  2.9490364
## b_NAP               -0.5770183 0.1542767 -0.89430239 -0.2779925
## b_Exposure10        -0.3921654 0.3734278 -1.07957393  0.3969519
## b_Exposure11        -1.1529676 0.3797490 -1.81743688 -0.2800094
## sd_Beach__Intercept  0.3036332 0.1558014  0.03965657  0.6790722
## sd_Beach__NAP        0.3494459 0.1563327  0.07779468  0.7054053</code></pre>
<div id="calcul-du-looic" class="section level2">
<h2>Calcul du LOOIC</h2>
<p>La fonction <code>loo</code> de <em>brms</em> compare différents modèles en fonction du critère estimé avec PSIS-LOO (LOOIC, égal à -2 fois la densité prédictive estimée pour la validtion croisée).</p>
<pre class="r"><code>loo1 &lt;- loo(mod1, mod2, compare = TRUE)</code></pre>
<pre><code>## Warning: Found 1 observations with a pareto_k &gt; 0.7 in model &#39;mod1&#39;. It is
## recommended to set &#39;moment_match = TRUE&#39; in order to perform moment matching for
## problematic observations.</code></pre>
<pre><code>## Warning: Found 3 observations with a pareto_k &gt; 0.7 in model &#39;mod2&#39;. It is
## recommended to set &#39;moment_match = TRUE&#39; in order to perform moment matching for
## problematic observations.</code></pre>
<pre class="r"><code>loo1</code></pre>
<pre><code>## Output of model &#39;mod1&#39;:
## 
## Computed from 4000 by 45 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo   -105.6  9.5
## p_loo        10.2  3.5
## looic       211.1 19.0
## ------
## Monte Carlo SE of elpd_loo is NA.
## 
## Pareto k diagnostic values:
##                          Count Pct.    Min. n_eff
## (-Inf, 0.5]   (good)     42    93.3%   917       
##  (0.5, 0.7]   (ok)        2     4.4%   127       
##    (0.7, 1]   (bad)       1     2.2%   157       
##    (1, Inf)   (very bad)  0     0.0%   &lt;NA&gt;      
## See help(&#39;pareto-k-diagnostic&#39;) for details.
## 
## Output of model &#39;mod2&#39;:
## 
## Computed from 4000 by 45 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo   -101.9  7.2
## p_loo        13.5  3.7
## looic       203.9 14.5
## ------
## Monte Carlo SE of elpd_loo is NA.
## 
## Pareto k diagnostic values:
##                          Count Pct.    Min. n_eff
## (-Inf, 0.5]   (good)     33    73.3%   796       
##  (0.5, 0.7]   (ok)        9    20.0%   255       
##    (0.7, 1]   (bad)       3     6.7%   37        
##    (1, Inf)   (very bad)  0     0.0%   &lt;NA&gt;      
## See help(&#39;pareto-k-diagnostic&#39;) for details.
## 
## Model comparisons:
##      elpd_diff se_diff
## mod2  0.0       0.0   
## mod1 -3.6       3.4</code></pre>
<p>Le résultat indique que le modèle 1 a un log de la densité prédictive inférieur de 3.6 comparé au modèle 2, sauf que l’erreur-type de cette différence (2e colonne) est de 3.4. Donc il n’est peut-être pas certain que le modèle 2 soit le meilleur.</p>
<p>De plus, R nous avertit que pour 4 observations (1 du modèle 1, 3 du modèle 2), l’estimé PSIS-LOO est instable avec un <span class="math inline">\(k &gt; 0.7\)</span> dans la distribution de Pareto. Cet avertissement signifie que pour ces observations, les poids utilisés pour l’approximation de la densité prédictive de validation croisée ont trop de valeurs extrêmes pour estimer leur variance. Tel que suggéré par le message, nous ré-évaluons le LOOIC avec l’argument <code>reloo = TRUE</code>, qui va réajuster le modèle en omettant chacune des observations problématiques, pour calculer la densité prédictive de validation croisée directement.</p>
<pre class="r"><code>loo_corr &lt;- loo(mod1, mod2, compare = TRUE, reloo = TRUE)</code></pre>
<pre><code>## 1 problematic observation(s) found.
## The model will be refit 1 times.</code></pre>
<pre><code>## 
## Fitting model 1 out of 1 (leaving out observation 10)</code></pre>
<pre><code>## Start sampling</code></pre>
<pre><code>## 3 problematic observation(s) found.
## The model will be refit 3 times.</code></pre>
<pre><code>## 
## Fitting model 1 out of 3 (leaving out observation 10)</code></pre>
<pre><code>## 
## Fitting model 2 out of 3 (leaving out observation 22)</code></pre>
<pre><code>## 
## Fitting model 3 out of 3 (leaving out observation 38)</code></pre>
<pre><code>## Start sampling
## Start sampling
## Start sampling</code></pre>
<pre class="r"><code>loo_corr</code></pre>
<pre><code>## Output of model &#39;mod1&#39;:
## 
## Computed from 4000 by 45 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo   -105.8  9.5
## p_loo        10.5  3.6
## looic       211.6 19.1
## ------
## Monte Carlo SE of elpd_loo is 0.1.
## 
## Pareto k diagnostic values:
##                          Count Pct.    Min. n_eff
## (-Inf, 0.5]   (good)     43    95.6%   157       
##  (0.5, 0.7]   (ok)        2     4.4%   127       
##    (0.7, 1]   (bad)       0     0.0%   &lt;NA&gt;      
##    (1, Inf)   (very bad)  0     0.0%   &lt;NA&gt;      
## 
## All Pareto k estimates are ok (k &lt; 0.7).
## See help(&#39;pareto-k-diagnostic&#39;) for details.
## 
## Output of model &#39;mod2&#39;:
## 
## Computed from 4000 by 45 log-likelihood matrix
## 
##          Estimate   SE
## elpd_loo   -103.1  7.7
## p_loo        14.7  4.3
## looic       206.3 15.5
## ------
## Monte Carlo SE of elpd_loo is 0.3.
## 
## Pareto k diagnostic values:
##                          Count Pct.    Min. n_eff
## (-Inf, 0.5]   (good)     36    80.0%   37        
##  (0.5, 0.7]   (ok)        9    20.0%   255       
##    (0.7, 1]   (bad)       0     0.0%   &lt;NA&gt;      
##    (1, Inf)   (very bad)  0     0.0%   &lt;NA&gt;      
## 
## All Pareto k estimates are ok (k &lt; 0.7).
## See help(&#39;pareto-k-diagnostic&#39;) for details.
## 
## Model comparisons:
##      elpd_diff se_diff
## mod2  0.0       0.0   
## mod1 -2.7       3.0</code></pre>
<p>Ici, la valeur des LOOIC a un peu changé par rapport au cas précédent. À titre de comparaison, le WAIC produit une différence plus grande entre les deux modèles.</p>
<pre class="r"><code>waic(mod1, mod2, compare = TRUE)</code></pre>
<pre><code>## Warning: 
## 6 (13.3%) p_waic estimates greater than 0.4. We recommend trying loo instead.</code></pre>
<pre><code>## Warning: 
## 9 (20.0%) p_waic estimates greater than 0.4. We recommend trying loo instead.</code></pre>
<pre><code>## Output of model &#39;mod1&#39;:
## 
## Computed from 4000 by 45 log-likelihood matrix
## 
##           Estimate   SE
## elpd_waic   -105.2  9.5
## p_waic         9.9  3.6
## waic         210.5 19.0
## 
## 6 (13.3%) p_waic estimates greater than 0.4. We recommend trying loo instead. 
## 
## Output of model &#39;mod2&#39;:
## 
## Computed from 4000 by 45 log-likelihood matrix
## 
##           Estimate   SE
## elpd_waic   -100.5  6.9
## p_waic        12.0  3.3
## waic         201.0 13.9
## 
## 9 (20.0%) p_waic estimates greater than 0.4. We recommend trying loo instead. 
## 
## Model comparisons:
##      elpd_diff se_diff
## mod2  0.0       0.0   
## mod1 -4.7       3.6</code></pre>
</div>
<div id="comparaison-avec-le-glmm" class="section level2">
<h2>Comparaison avec le GLMM</h2>
<p>Lorsque nous avions ajusté ces modèles avec des GLMM au cours 5, l’AIC était plus faible pour le modèle 1, avec un effet aléatoire sur l’ordonnée à l’origine seulement. Pourquoi la méthode bayésienne donne-t-elle un résultat différent?</p>
<ul>
<li><p>D’abord, l’utilisation de distributions <em>a priori</em> contraint les valeurs des paramètres de façon à ce qu’un modèle plus complexe présente un surajustement moindre.</p></li>
<li><p>Ensuite, l’AIC et les critères bayésiens sont basés sur des prédictions différentes. Supposons que deux modèles diffèrent par un paramètre <span class="math inline">\(\theta\)</span>. L’AIC compare les prédictions lorsque ce paramètre est omis, ce qui implique par exemple <span class="math inline">\(\theta = 0\)</span>, avec les prédictions à la valeur estimée du maximum de vraisemblance <span class="math inline">\(\hat{\theta}\)</span>. En contrepartie, les prédictions bayésiennes du modèle incluant <span class="math inline">\(\theta\)</span> sont une moyenne réalisée à partir de la distribution <em>a posteriori</em> de <span class="math inline">\(\theta\)</span>, qui va inclure des valeurs proches de 0 si ce cas a une probabilité <em>a posteriori</em> non-négligeable.</p></li>
</ul>
<p>Pour ces deux raisons, les prédictions du maximum de vraisemblance et de l’approche bayésienne diffèrent sauf dans des cas très particuliers, ex.: un modèle linéaire où la distribution <em>a priori</em> a peu d’importance et la distribution <em>a posteriori</em> de tous les paramètres est symétrique.</p>
</div>
<div id="superposition-des-modèles" class="section level2">
<h2>Superposition des modèles</h2>
<p>Le résultat de <code>loo</code> contient un élément pour chacun des modèles comparés. Chacun de ces éléments contient une matrice <code>pointwise</code> qui présente notamment la valeur estimée du log de la densité prédictive <span class="math inline">\(\log p(y_i | y_{-i})\)</span> pour chaque point <span class="math inline">\(i\)</span> (<code>elpd_loo</code>) et l’erreur-type de cet estimé (<code>mcse_elpd_loo</code>).</p>
<pre class="r"><code>head(loo1$loos$mod1$pointwise)</code></pre>
<pre><code>##       elpd_loo mcse_elpd_loo      p_loo    looic influence_pareto_k
## [1,] -3.035422   0.010108673 0.21491808 6.070843          0.2736016
## [2,] -2.631103   0.009949967 0.17020507 5.262206          0.3098142
## [3,] -2.552925   0.008736143 0.12135383 5.105851          0.2586973
## [4,] -4.569708   0.021133985 0.65050744 9.139416          0.3687250
## [5,] -2.204221   0.003305800 0.02572645 4.408443          0.3002091
## [6,] -2.226006   0.005473939 0.06371198 4.452012          0.2461702</code></pre>
<p>Si nous voulions faire combiner les prédictions de ces deux modèles, la fonction <code>stacking_weights</code> du package <em>loo</em> permet de déterminer les poids pour la superposition optimale des deux modèles. Cette fonction requière une matrice avec une colonne par modèle, correspondant à la colonne <code>elpd_loo</code> de la matrice <code>pointwise</code> mentionnée ci-dessus.</p>
<pre class="r"><code>library(loo)
stacking_weights(cbind(loo1$loos$mod1$pointwise[,1], loo1$loos$mod2$pointwise[,1]))</code></pre>
<pre><code>## Method: stacking
## ------
##        weight
## model1 0.037 
## model2 0.963</code></pre>
<pre class="r"><code>stacking_weights(cbind(loo_corr$loos$mod1$pointwise[,1], loo_corr$loos$mod2$pointwise[,1]))</code></pre>
<pre><code>## Method: stacking
## ------
##        weight
## model1 0.127 
## model2 0.873</code></pre>
<p>Pour l’estimé du PSIS-LOO avec correction des valeurs problématiques, nous voyons qu’un poids beaucoup plus grand est donné au modèle 2. Tel que mentionné plus haut, puisque les prédictions du modèle 2 sont basées sur la distribution <em>a posteriori</em> entière de <code>sd_Beach__NAP</code>, cela inclut des cas où l’écart-type de cet effet aléatoire s’approche de 0 et on s’approche donc du modèle 1.</p>
<p>Nous terminons ce cours en présentant des exemples récents d’application des modèles hiérarchiques bayésiens avec Stan en écologie.</p>
</div>
</div>
<div id="application-modèle-prédateur-proie" class="section level1">
<h1>Application: modèle prédateur-proie</h1>
<p>Rosenbaum et al. (2019) modélisent la dynamique de population d’un système prédateur-proie-ressource dans un environnement contrôlé (chemostat). Le prédateur est une espèce de rotifère (animal microscopique) et la proie est une algue unicellulaire dont la croissance dépend de la concentration d’azote (ressource limitante).</p>
<div id="modèle-théorique" class="section level2">
<h2>Modèle théorique</h2>
<p>Les auteurs supposent que la concentration d’azote <span class="math inline">\(S\)</span>, la densité des algues <span class="math inline">\(A\)</span> et celle des rotifères <span class="math inline">\(R\)</span> varient au cours du temps selon les équations suivantes:</p>
<p><span class="math display">\[\frac{dS}{dt} = \delta S^* - \frac{1}{c_A} \frac{f_A S}{h_A + S} A - \delta S\]</span></p>
<p>Cette équation indique que le taux de variation de la concentration d’azote dépend de (1) l’influx d’azote <span class="math inline">\(\delta S^*\)</span> (<span class="math inline">\(\delta\)</span> est le débit du chemostat et <span class="math inline">\(S^*\)</span> la concentration dans la solution entrante); (2) la consommation d’azote par les algues (<span class="math inline">\(c_A\)</span> est le facteur de conversion, <span class="math inline">\(f_A\)</span> est le taux de croissance maximal et <span class="math inline">\(h_A\)</span> le point de demi-saturation) et (3) le flux de sortie <span class="math inline">\(\delta S\)</span>.</p>
<p><span class="math display">\[\frac{dA}{dt} = \frac{f_A S}{h_A + S} A - \frac{1}{c_R} \frac{f_R A}{h_R + A} R - \delta A\]</span></p>
<p>Cette équation indique que le taux de variation de la densité d’algues dépend de (1) la consommation d’azote par les algues, (2) la consommation d’algues par les rotifères (facteur de conversion <span class="math inline">\(c_R\)</span>, taux de croissance maximal <span class="math inline">\(f_R\)</span> et point de demi-saturation <span class="math inline">\(h_R\)</span>) et (3) le flux de sortie <span class="math inline">\(\delta A\)</span>.</p>
<p><span class="math display">\[\frac{dR}{dt} = \frac{f_R A}{h_R + A} R - \delta R\]</span></p>
<p>Finalement, le taux de variation de la densité de rotifères dépend de leur consommation d’algues et du flux de sortie.</p>
</div>
<div id="données-et-modèle-statistique" class="section level2">
<h2>Données et modèle statistique</h2>
<p>Les auteurs ont mesuré la concentration quotidienne d’algues et de rotifères pour une vingtaine de jours dans 18 réplicats de cette expérience. Dans certains réplicats, les séries temporelles montraient des concentrations stables, tandis que d’autres montraient une dynamique cyclique.</p>
<p>Pour cette expérience, les paramètres <span class="math inline">\(\delta\)</span>, <span class="math inline">\(S^*\)</span>, <span class="math inline">\(h_A\)</span> et <span class="math inline">\(h_R\)</span> sont connus, tandis que les taux de croissance maximaux des deux organismes (<span class="math inline">\(f_A\)</span> et <span class="math inline">\(f_R\)</span>) et les facteurs de conversion (<span class="math inline">\(c_A\)</span> et <span class="math inline">\(c_R\)</span>) doivent être estimés à partir des données. Voici un résumé du modèle Stan implémentant ce modèle:</p>
<ul>
<li><p>Les logarithmes des paramètres <span class="math inline">\(f_A\)</span>, <span class="math inline">\(f_R\)</span>, <span class="math inline">\(c_A\)</span> et <span class="math inline">\(c_R\)</span> varient de façon aléatoire entre les réplicats, selon une distribution normale dont la moyenne et l’écart-type sont des paramètres à estimer.</p></li>
<li><p>Les concentrations de chaque élément du système au début de l’expérience (<span class="math inline">\(S_0\)</span>, <span class="math inline">\(A_0\)</span> et <span class="math inline">\(R_0\)</span>) sont des paramètres à estimer.</p></li>
<li><p>Pour une valeur donnée des paramètres, la série de trois équations ci-dessus est résolue numériquement pour obtenir les séries temporelles de <span class="math inline">\(S\)</span>, <span class="math inline">\(A\)</span> et <span class="math inline">\(R\)</span>. (Stan permet de résoudre des systèmes d’équations différentielles dans un modèle.)</p></li>
<li><p>Les observations de <span class="math inline">\(A\)</span> et <span class="math inline">\(R\)</span> suivent une distribution log-normale autour de leur vraie valeur, avec un écart-type à estimer.</p></li>
</ul>
<p>Les auteurs ont assigné à tous les paramètres à estimer des distributions <em>a priori</em> avec contraintes légères (<em>weakly informative prior</em>) basées sur des expériences passées avec ce type de système.</p>
</div>
<div id="simulations" class="section level2">
<h2>Simulations</h2>
<p>Les auteurs ont réalisé des simulations à partir du modèle complet, avec des paramètres tirés de leur distribution <em>a priori</em>, afin d’assurer que le modèle ajusté aux résultats de ces simulations soit capable de retrouver les vraies valeurs des paramètres <span class="math inline">\(f_A\)</span>, <span class="math inline">\(f_R\)</span>, <span class="math inline">\(c_A\)</span> et <span class="math inline">\(c_R\)</span> (autrement dit, que les paramètres soient <em>identifiables</em>).</p>
<p>La Figure 1 de cette étude reproduite ci-dessous montre la distribution <em>a posteriori</em> de l’erreur d’estimation des paramètres pour différentes simulations. Ce test a permis aux auteurs de déterminer que lorsque les populations des deux espèces sont stables plutôt que cycliques (résultats du haut en vert), trois des quatres paramètres sont difficiles à estimer précisément.</p>
<p><img src="../images/Rosenbaum2019_Fig1.jpg" /> <em>Source: Rosenbaum et al. 2019, Fig.1</em></p>
</div>
<div id="ajustement-du-modèle" class="section level2">
<h2>Ajustement du modèle</h2>
<p>À partir du modèle ajusté aux observations, les auteurs ont produit des estimations <em>a posteriori</em> des concentrations <span class="math inline">\(S\)</span>, <span class="math inline">\(A\)</span> et <span class="math inline">\(R\)</span> à chaque jour pour chacun des réplicats (Figure 3, reproduite ci-dessous, avec les points correspondant aux valeurs observées de <span class="math inline">\(A\)</span> et <span class="math inline">\(R\)</span>). Puisque la concentration d’azote <span class="math inline">\(S\)</span> (en haut en bleu) n’était pas mesurée, la précision de son estimation dépend de la précision des paramètres du modèle, c’est pourquoi elle est moins précise dans le cas où les populations sont stables plutôt que cycliques (rangée du haut).</p>
<p><img src="../images/Rosenbaum2019_Fig3.jpg" /> <em>Source: Rosenbaum et al. 2019, Fig.3.</em></p>
<p>En comparant la dynamique estimée par le modèle aux points d’observation, on voit que le modèle suit plus précisément les observations des concentrations d’algues (au milieu en vert) que celles des rotifères (en bas en rouge). Une des raisons possibles évoquées par les auteurs pour expliquer ces résultats est que la croissance de la population d’algues dépend de la concentration d’azote non-mesurée, donc le modèle a la flexibilité d’ajuster cette concentration pour bien reproduire la dynamique des algues, ce qui n’est pas le cas pour les rotifères dont la croissance dépend de la population d’algues.</p>
</div>
</div>
<div id="application-dispersion-des-graines-et-semis" class="section level1">
<h1>Application: dispersion des graines et semis</h1>
<p>Cet exemple présente une étude que j’ai réalisée avec des collaborateurs afin d’estimer les courbes de dispersion des graines et des semis en fonction de la distance pour différentes espèces de la forêt de l’île Barro Colorado au Panama (Marchand et al. 2020).</p>
<div id="modèle-et-données" class="section level2">
<h2>Modèle et données</h2>
<p>Le site d’étude est une parcelle de 50 ha (1 km x 0.5 km) du Smithsonian Tropical Research Institute (STRI) où tous les arbres avec un DHP &gt;1 cm sont cartographiés et mesurés aux 5 ans depuis 1985. Les chercheurs du STRI ont aussi fait la collecte annuelle et l’identification des graines dans 500 capteurs (filets) dispersés dans cette parcelle, ainsi que le comptage des nouveaux semis dans des placettes autour de ces capteurs.</p>
<p>La dispersion des graines est modélisée séparément pour chacune des principales espèces d’arbres. Le nombre de graines trouvées dans le capteur <span class="math inline">\(j\)</span> lors de l’année <span class="math inline">\(t\)</span> suit une distribution binomiale négative dont la moyenne <span class="math inline">\(\mu_{jt}\)</span> est donnée par l’équation suivante:</p>
<p><span class="math display">\[\mu_{jt} = a \sum_i Q(b_{it}) F(r_{ij})\]</span></p>
<p>Pour chaque arbre <span class="math inline">\(i\)</span> de cette espèce, on multiplie la production de graines <span class="math inline">\(Q\)</span> par la fonction de dispersion <span class="math inline">\(F\)</span>, qui donne la probabilité qu’une graine tombe dans une surface d’un mètre carré située à une distance <span class="math inline">\(r_{ij}\)</span>. On fait ensuite la somme pour tous les arbres et on multiplie par l’aire du capteur <span class="math inline">\(a\)</span>.</p>
<p>La production de graines d’un arbre est supposée proportionnelle à sa surface terrière <span class="math inline">\(b\)</span>.</p>
<p><span class="math display">\[Q(b_{it}) = e^{\beta_t} b_{it}\]</span></p>
<p>Le logarithme de la constante de proportionalité, <span class="math inline">\(\beta_t\)</span>, varie d’une année à l’autre selon une distribution normale dont les paramètres doivent être estimés.</p>
<p><span class="math display">\[\beta_t \sim \text{N}(\mu_{\beta}, \sigma_{\beta})\]</span></p>
<p>Le même modèle peut être utilisé pour estimer la dispersion des semis par rapport aux parents potentiels.</p>
<p>Notre objectif principal était de déterminer la forme de la fonction de dispersion <span class="math inline">\(F\)</span> pour les graines et semis de différentes espèces, ainsi que le succès relatif de germination (rapport entre le nombre de semis et de graines) en fonction de la distance du parent.</p>
<p>La figure ci-dessous montre les différentes fonctions de dispersion que nous avons considérées. Chacune contient deux paramètres à ajuster à partir des données.</p>
<p><img src="../images/Marchand2020_disp.png" /></p>
<p>Le problème d’estimation de courbes de dispersion pose deux problèmes pour lesquels l’approche bayésienne offre des solutions intéressantes:</p>
<ul>
<li><p>La dispersion des graines suit un patron <em>leptokurtique</em>, c’est-à-dire que la plupart des graines tombe près du parent, mais une petite proportion peut atteindre des distances extrêmes (plusieurs kilomètres) sous l’action du vent et des animaux. Cependant, nos données ne nous permettent pas d’observer la dispersion sur de longues distances ou de très courtes distances. Dans cette situation, un ajustement aux données sans contraintes peut mener à une fonction de dispersion non-réaliste (ex.: distance de dispersion médiane &lt; 10 cm et moyenne &gt; 10 km).</p></li>
<li><p>Il est probable qu’aucune des fonctions de dispersion présentées ci-dessus n’est tout à fait appropriée. Dans ce cas, nous voudrions estimer des caractéristiques de la dispersion (distance moyenne des graines et des semis, taux de germination relatif en fonction de la distance) en tenant compte de l’incertitude sur la forme de la fonction de dispersion.</p></li>
</ul>
<p>Pour résoudre le deuxième problème, nous avons estimé les paramètres de chacune des 5 fonctions de dispersion pour chaque espèce et avons utilisé la superposition de modèles pour obtenir des prédictions multi-modèles des caractéristiques de dispersion qui nous intéressent. Avant d’effectuer cette superposition, nous avons utilisé la vérification des prédictions <em>a posteriori</em> pour éliminer les modèles très mal ajustés aux données: par exemple, ceux qui ne donnaient pas des valeurs plausibles pour le nombre total de graines observées dans les capteurs, ou pour le nombre de zéros observés.</p>
<p>Pour résoudre le premier problème, nous avons choisi des distributions <em>a priori</em> pour les paramètres de chaque fonction de dispersion, afin que les valeurs plausibles de la distance médiane et moyenne de dispersion soient de l’ordre de 1 m à 1 km; cela ne signifie pas que la distribution <em>a posteriori</em> est confinée à cet intervalle, mais que ces valeurs plus plausibles sont favorisées sauf si les données appuient fortement des valeurs plus extrêmes. Nous avons aussi choisi des distributions <em>a priori</em> basées sur la plausibilité biologique pour les paramètres de la production de graines.</p>
</div>
<div id="résultats" class="section level2">
<h2>Résultats</h2>
<p>La figure ci-dessous présente un exemple des courbes de dispersion et du taux de germination relatif que nous avons estimées à partir de la superposition des modèles. Dans les deux cas, les semis se trouvent en moyenne plus loin du parent que les graines. Pour l’espèce à gauche, le taux de germination augmente de façon continue entre 1 et 100 m de distance du parent, tandis que pour l’espèce à droite, il semble atteindre un plateau entre 10 et 100 m.</p>
<p><img src="../images/Marchand2020_res.png" /></p>
</div>
</div>
<div id="références" class="section level1">
<h1>Références</h1>
<p>Marchand, P., Comita, L. S., Wright, S. J., Condit, R., Hubbell, S. P., &amp; Beckman, N. G. (2020). Seed-to-seedling transitions exhibit distance-dependent mortality but no strong spacing effects in a Neotropical forest. <em>Ecology</em>, 101(2), e02926. <a href="doi:10.1002/ecy.2926" class="uri">doi:10.1002/ecy.2926</a>.</p>
<p>Rosenbaum, B., Raatz, M., Weithoff, G., Fussmann, G.F. et Gaedke, U. (2019) Estimating parameters from multiple time series of population dynamics using bayesian inference. <em>Frontiers in Ecology and Evolution</em> 6, 234. doi: 10.3389/fevo.2018.00234.</p>
<p>Vehtari, A., Gelman, A. et Gabry, J. (2017) Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. <em>Statistics and Computing</em> 27(5), 1413–1432. <a href="doi:10.1007/s11222-016-9696-4" class="uri">doi:10.1007/s11222-016-9696-4</a>.</p>
<p>Yao, Y., Vehtari, A., Simpson, D. et Gelman, A. (2018) Using stacking to average Bayesian predictive distributions. Bayesian Analysis 13(3), 917–1007. <a href="doi:10.1214/17-BA1091" class="uri">doi:10.1214/17-BA1091</a>.</p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
