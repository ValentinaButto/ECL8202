<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Modèles hiérarchiques bayésiens 2</title>
    <meta charset="utf-8" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="styles-xar8202.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Modèles hiérarchiques bayésiens 2
### ECL8202 - Hiver 2020

---




# Contenu du cours

- Révision: Comparaison et sélection de modèles

- Approche bayésienne pour la comparaison de modèles

- Comparaison de modèles avec *loo* et *brms*

- Plus d'exemples de modèles bayésiens en écologie

---

class: inverse, center, middle

# Comparaison et sélection de modèles

---

# Comparaison et sélection de modèles

- Différents modèles statistiques visant à expliquer les mêmes données: comment déterminer quel modèle représente le mieux le phénomène étudié? 

--

- Objectif: Optimiser la capacité du modèle à **prédire de nouvelles observations** du phénomène.


---

# Sous-ajustement et surajustement

- Modèle trop simple: erreur systématique, effets importants omis (biais, sous-ajustement).

--

- Modèle trop complexe: erreur aléatoire, représente les associations "accidentelles" d'un échantillon (variance, surajustement).

--

- Avec plus de données, on peut ajuster un modèle plus complexe.

![](../images/biais_variance.png)

---

# Ensemble de validation

- Mettre de côté une partie des données (~ 20 à 30%) pour évaluer la performance prédictive.

--

- Pas pratique sauf si l'échantillon est grand.

---

# Validation croisée

- Évaluer la performance prédictive sur de nouvelles observations tout en utilisant l'ensemble des données pour l'entraînement. 

--

- On divise aléatoirement les observations en groupes et on mesure la qualité des prédictions pour un groupe selon le modèle ajusté au reste des observations.

--

- Une observation par groupe (*leave-one-out cross-validation*); `\(k\)` groupes (*k-fold cross-validation*).

--

- Méthode coûteuse en calcul, car il faut réajuster le modèle plusieurs fois.

---

# Critère d'information d'Akaike (AIC)

- Basé sur la théorie de l'information, produit des résultats consistents avec la validation croisée *leave-one-out* si l'échantillon est assez grand.

`$$AIC = -2 \log L + 2 K$$`

--

- Premier terme: ajustement aux données observées.

- Deuxième terme: pénalité pour la complexité du modèle.

---

# Comparaison de modèles avec l'AIC

- Seule la différence d'AIC entre modèles est interprétable.

`$$\Delta AIC = AIC - \min AIC$$`

--

- Rapport de plausibilité (*evidence ratio*) de chaque modèle vs. celui avec un AIC minimal.

`$$e^{-\frac{\Delta AIC}{2} }$$`

--

- Exemple: `\(\Delta AIC = 2\)`, rapport de 0.37 (~3 fois moins probable); `\(\Delta AIC = 10\)`, rapport de ~0.0067 (~150 fois moins probable).

---

# Prédictions multi-modèles

- Poids d'Akaike pour chacun des `\(m\)` modèles candidats:

`$$w_i = \frac{e^{\frac{-\Delta AIC_i}{2}}}{\sum_{j=1}^{m} e^{\frac{-\Delta AIC_j}{2}}}$$`

--

- Prédiction d'une nouvelle observation `\(\tilde{y}\)` basée sur la moyenne pondérée:

`$$\tilde{y} = \sum_{j = 1}^m w_j \tilde{y_j}$$` 

--

- Les prédictions multi-modèles sont souvent plus précises que celles obtenues en considérant seulement le meilleur modèle, car elles tiennent compte de l'incertitude sur la forme du modèle.

---

class: inverse, center, middle

# Approche bayésienne pour la comparaison de modèles

---

# Densité prédictive

- Pour un modèle estimé par maximum de vraisemblance, prédictions obtenues en fixant les paramètres à leur valeur estimée.

- Vraisemblance de la nouvelle observation: `\(p(\tilde{y} | \hat{\theta})\)`. 

--

- Prédictions bayésiennes font la moyenne de `\(p(\tilde{y} | \theta)\)` en fonction de la distribution *a posteriori* des `\(\theta\)`.

---

# Densité prédictive

`$$p(\tilde{y} | y) = \int p(\tilde{y} | \theta) p(\theta | y) \text{d}\theta$$`

--

- En pratique, avec `\(S\)` vecteurs `\(\theta_{(1)}, ..., \theta_{(S)}\)` tirés de la distribution *a posteriori* par un algorithme de Monte-Carlo: 

`$$p(\tilde{y} | y) = \frac{1}{S} \sum_{j = 1}^S p(\tilde{y} | \theta_{(j)})$$`

--

- Plus facile de travailler avec le logarithme de `\(p(\tilde{y} | y)\)`.

---

# Critères de sélection bayésiens

- On peut utiliser la validation croisée dans un contexte bayésien, mais l'ajustement répété du modèle est très coûteux.

--

- L'AIC s'applique mal: on ne connait pas le maximum de vraisemblance, les `\(K\)` paramètres ne sont pas tout à fait libres en raison des contraintes.

---

# DIC

Critère d'information de la déviance:

`$$DIC = -2 \log p(y | \bar{\theta}) + 2 p_D$$`

- `\(\bar{\theta}\)`: moyenne *a posteriori* de `\(\theta\)`

- `\(p_D\)`: nombre effectif de paramètres

--

- Le plus proche de l'AIC, évalue les prédictions à une seule valeur de `\(\theta\)` (pas une approche bayésienne).

---

# WAIC

Critère de Watanabe-Akaike (WAIC):

`$$WAIC = -2 \sum_{i=1}^n \log \left( \frac{1}{S} \sum_{j = 1}^S p(y_i | \theta_{(j)}) \right) + 2 p_W$$` 

- Premier terme: densité prédictive conjointe des observations.

--

- Pénalité `\(p_W\)`: somme des variances du logarithme de la densité prédictive à chaque point:

`$$p_W = \sum_{i=1}^n \text{Var}_j \left(\log p(y_i | \theta_{(j)}) \right)$$`

--

- Calculé avec la fonction `waic` dans *brms*.

---

# PSIS-LOO

- PSIS = *Pareto smoothed importance sampling*, LOO = *leave-one-out*.

--

- Vise à estimer la densité prédictive qui serait obtenue par validation croisée *leave-one-out* pour chaque point, donc à partir du jeu de données `\(y_{-i}\)` excluant le point `\(i\)`.

`$$p(y_i | y_{-i}) = \int p(y_i | \theta) p(\theta | y_{-i}) \text{d}\theta$$` 

--

- Approximation basée sur la moyenne des `\(p(y | \theta_{(j)})\)`, mais avec une pondération particulière.

--

- Pondération ajustée pour que les poids extrêmes suivent un modèle théorique (distribution de Pareto).

---

# PSIS-LOO

- Implémentée dans le package R *loo*, accessible par la fonction `loo` dans *brms*.

--

- Diagnostic pour chaque point: l'ajustement des poids pour `\(y_i\)` est une distribution de Pareto avec un paramètre `\(k\)`. Si `\(k &gt; 0.7\)`, l'approximation est instable.

--

- On peut ensuite effectuer la validation croisée pour les observations `\(y_i\)` problématiques seulement.

--

- Résultat de cette méthode: logarithme de la densité prédictive `\(elpd_{loo}\)`, soit la somme de `\(\log p(y_i | y_{-i})\)`.

- LOOIC: `\(-2 elpd_{loo}\)` 

---

# Comparaison des méthodes

- PSIS-LOO plus précise que le WAIC, surtout pour les petits échantillons.

- WAIC plus rapide à calculer.

--

- Les deux méthodes basées sur la densité prédictive (WAIC et PSIS-LOO) sont préférées au DIC.

--

- Cependant, WAIC et PSIS-LOO supposent que les `\(y_i\)` sont indépendants conditionnellement aux `\(\theta\)`. Ex.: pas de corrélation temporelle ou spatiale.

---

# Prédictions multi-modèles

`$$\tilde{y} = \sum_{j = 1}^m w_j \tilde{y_j}$$` 

--

- Comme pour l'AIC, nous pourrions définir des poids selon les différences d'IC entre deux modèles (ex.: avec le WAIC ou LOOIC).

--

- Est-ce que des poids basés sur les rapports de plausibilité sont toujours optimaux (ex.: redondance entre modèles)?

---

# Superposition des modèles (*model stacking*)

`$$\tilde{y} = \sum_{j = 1}^m w_j \tilde{y_j}$$` 

- Objectif: trouver les poids `\(w_j\)` qui minimisent l'erreur de prédiction de la moyenne pondérée.

--

- Le package *loo* contient des méthodes pour calculer ces poids optimaux directement avec le résultat de la méthode PSIS-LOO (Yao et al. 2018).

---

class: inverse, center, middle

# Comparaison de modèles avec *loo* et *brms*

---

# Exemple

- Jeu de données `rikz` utilisé dans les cours précédents.


```r
rikz &lt;- read.csv("../donnees/rikz.csv")
rikz$Exposure &lt;- as.factor(rikz$Exposure)
head(rikz)
```

```
##   Sample Richness Exposure    NAP Beach
## 1      1       11       10  0.045     1
## 2      2       10       10 -1.036     1
## 3      3       13       10 -1.336     1
## 4      4       11       10  0.616     1
## 5      5       10       10 -0.684     1
## 6      6        8        8  1.190     2
```

---

# Modèles candidats

- Régression de Poisson pour la richesse spécifique en fonction de *NAP* et *Exposure*, avec un effet aléatoire de la plage sur l'ordonnée à l'origine.

.code60[

```r
library(brms)

rikz_prior &lt;- c(set_prior("normal(0, 1)", class = "b"),
                set_prior("normal(2, 1)", class = "Intercept"),
                set_prior("normal(0, 0.5)", class = "sd"))

mod1 &lt;- brm(Richness ~ NAP + Exposure + (1 | Beach), data = rikz, 
            family = poisson, prior = rikz_prior,
            control = list(adapt_delta = 0.99))
```
]





--

- Modèle avec en plus un effet aléatoire de la plage sur le coefficient du *NAP*.

.code60[

```r
mod2 &lt;- brm(Richness ~ NAP + Exposure + (1 + NAP | Beach), data = rikz, 
            family = poisson, prior = rikz_prior,
            control = list(adapt_delta = 0.99))
```
]



---

# Résultats des deux modèles 

.code60[

```r
posterior_summary(mod1, pars = "b|sd")
```

```
##                       Estimate  Est.Error        Q2.5      Q97.5
## b_Intercept          2.3884144 0.27840105  1.75083676  2.8785613
## b_NAP               -0.5022124 0.07176014 -0.64582122 -0.3608672
## b_Exposure10        -0.4691733 0.30487920 -1.01123717  0.2171970
## b_Exposure11        -1.1705471 0.32929566 -1.74728595 -0.4413458
## sd_Beach__Intercept  0.2373889 0.14023472  0.02249371  0.5754880
```

```r
posterior_summary(mod2, pars = "b|sd")
```

```
##                       Estimate Est.Error        Q2.5      Q97.5
## b_Intercept          2.3691869 0.3091490  1.69473311  2.9240565
## b_NAP               -0.5775489 0.1564899 -0.89854093 -0.2835272
## b_Exposure10        -0.3828538 0.3611243 -1.06347491  0.3860103
## b_Exposure11        -1.1510663 0.3621368 -1.79881037 -0.3321635
## sd_Beach__Intercept  0.3083409 0.1534932  0.04834567  0.6596843
## sd_Beach__NAP        0.3432250 0.1571353  0.05545215  0.7021380
```
]

---

# Calcul du LOOIC


```r
loo1 &lt;- loo(mod1, mod2, compare = TRUE)
```

```
## Warning: Found 1 observations with a pareto_k &gt; 0.7 in model 'mod1'. It is
## recommended to set 'reloo = TRUE' in order to calculate the ELPD without
## the assumption that these observations are negligible. This will refit
## the model 1 times to compute the ELPDs for the problematic observations
## directly.
```

```
## Warning: Found 2 observations with a pareto_k &gt; 0.7 in model 'mod2'. It is
## recommended to set 'reloo = TRUE' in order to calculate the ELPD without
## the assumption that these observations are negligible. This will refit
## the model 2 times to compute the ELPDs for the problematic observations
## directly.
```

---

# Calcul du LOOIC


```r
loo1
```

```
##              LOOIC    SE
## mod1        212.08 19.49
## mod2        205.55 15.57
## mod1 - mod2   6.53  6.00
```

---

# Recalcul des points problématiques


```r
loo_corr &lt;- loo(mod1, mod2, compare = TRUE, reloo = TRUE)
loo_corr
```

```
##              LOOIC    SE
## mod1        211.91 19.37
## mod2        205.07 14.96
## mod1 - mod2   6.84  6.63
```

---

# Résultat du WAIC


```r
waic(mod1, mod2, compare = TRUE)
```

```
##               WAIC    SE
## mod1        211.02 19.15
## mod2        200.92 13.85
## mod1 - mod2  10.10  7.41
```

---

# Comparaison avec le GLMM

- Au cours 5, l'AIC était plus faible pour le modèle 1 (effet aléatoire sur l'ordonnée à l'origine seulement).

--

- Dans l'approche bayésienne, les distributions *a priori* contraignent les valeurs des paramètres, donc un modèle plus complexe est moins surajusté. 

--

- Les prédictions des deux approches sont différentes.

--

- Ex.: Pour choisir d'inclure ou non un paramètre `\(\theta\)`, l'AIC compare les prédictions pour `\(\theta = \hat{\theta}\)` avec celles pour `\(\theta = 0\)`.

--

- Les prédictions bayésiennes font la moyenne sur la distribution *a posteriori* de `\(\theta\)`, incluant des valeurs proches de 0 si elles sont probables.

---

# Superposition des modèles

- Résultat de `loo` contient un élément par modèle comparé et chaque élément contient une matrice `pointwise`.

.code60[

```r
head(loo1$mod1$pointwise)
```

```
##       elpd_loo mcse_elpd_loo      p_loo    looic
## [1,] -3.040982   0.009259136 0.21210934 6.081964
## [2,] -2.632146   0.011203855 0.17607859 5.264291
## [3,] -2.557157   0.010528233 0.12504570 5.114314
## [4,] -4.561902   0.016877960 0.63245392 9.123804
## [5,] -2.204902   0.003298531 0.02559070 4.409804
## [6,] -2.215077   0.005003861 0.05788407 4.430154
```
]

--

- `elpd_loo`: valeur estimée de `\(\log p(y_i | y_{-i})\)` pour chaque point `\(i\)`.

- `mcse_elpd_loo`: erreur-type de cette valeur.

---

# Superposition des modèles

- Fonction `stacking_weights` du package *loo*: déterminer les poids optimaux de superposition des modèles. 

--

- Requière une matrice avec la colonne `elpd_loo` de `pointwise` pour chaque modèle.

---

# Superposition des modèles


```r
library(loo)
stacking_weights(cbind(loo1$mod1$pointwise[,1], loo1$mod2$pointwise[,1]))
```

```
## Method: stacking
## ------
##        weight
## model1 0.000 
## model2 1.000
```

```r
stacking_weights(cbind(loo_corr$mod1$pointwise[,1], loo_corr$mod2$pointwise[,1]))
```

```
## Method: stacking
## ------
##        weight
## model1 0.019 
## model2 0.981
```

---

# Références

Vehtari, A., Gelman, A. et Gabry, J. (2017) Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. *Statistics and Computing* 27(5), 1413--1432. doi:10.1007/s11222-016-9696-4.

Yao, Y., Vehtari, A., Simpson, D. et Gelman, A. (2018) Using stacking to average Bayesian predictive distributions. Bayesian Analysis 13(3), 917--1007. doi:10.1214/17-BA1091.

---

class: inverse, center, middle

# Application: modèle prédateur-proie

---

# Application: modèle prédateur-proie

- Rosenbaum et al. (2019) Estimating parameters from multiple time series of population dynamics using bayesian inference.

- Système prédateur-proie-ressource dans un environnement contrôlé (chemostat).

--

- azote (ressource) -&gt; algue (proie) -&gt; rotifère (prédateur)

---

# Modèle

### Concentration d'azote `\(S\)`

`$$\frac{dS}{dt} = \delta S^* - \frac{1}{c_A} \frac{f_A S}{h_A + S} A - \delta S$$`

- Terme 1: Influx d'azote

--

- Terme 2: Consommation d'azote par les algues

--

- Terme 3: Flux de sortie

---

# Modèle

### Densité d'algues `\(A\)`

`$$\frac{dA}{dt} = \frac{f_A S}{h_A + S} A - \frac{1}{c_R} \frac{f_R A}{h_R + A} R - \delta A$$`

- Terme 1: consommation d'azote

- Terme 2: consommation d'algues par les rotifères

- Terme 3: flux de sortie

---

# Modèle

### Densité de rotifères `\(R\)`

`$$\frac{dR}{dt} = \frac{f_R A}{h_R + A} R - \delta R$$`

---

# Données 

- Mesures quotidiennes de `\(A\)` et `\(R\)` pour ~20 jours dans 18 réplicats. 

--

- Certains réplicats montrent des densités stables, d'autres montrent une dynamique cyclique.

--

- Les paramètres `\(\delta\)`, `\(S^*\)`, `\(h_A\)` et `\(h_R\)` sont connus. 

--

- Les taux de croissance maximaux, `\(f_A\)` et `\(f_R\)`, ainsi que les facteurs de conversion, `\(c_A\)` et `\(c_R\)`, sont à estimer. 

--

- Aussi à estimer: les valeurs `\(S_0\)`, `\(A_0\)` et `\(R_0\)` pour chaque réplicat au début de l'expérience.

---

# Modèle bayésien

- Effets aléatoires: le logarithme des paramètres `\(f_A\)`, `\(f_R\)`, `\(c_A\)` et `\(c_R\)` varie entre les réplicats, suivant une distribution normale.

--

- Pour une valeur donnée des paramètres, Stan résout numériquement les équations de `\(S\)`, `\(A\)` et `\(R\)`. 

--

- Les observations de `\(A\)` et `\(R\)` suivent une distribution log-normale autour de leur vraie valeur, avec un écart-type à estimer.

--

- Tous les paramètres ont des distributions *a priori* avec contraintes légères (*weakly informative prior*) basées sur des expériences passées. 

---

# Simulations

- Ajustement du modèle à des données simulées à partir des distributions *a priori*. 

--

- But: Vérifier que les paramètres `\(f_A\)`, `\(f_R\)`, `\(c_A\)` et `\(c_R\)` sont identifiables.

--

- Résultat: excepté `\(f_R\)`, les autres paramètres sont difficiles à estimer lorsque les populations sont stables plutôt que cycliques.

---

# Simulations

![](../images/Rosenbaum2019_Fig1_half.jpg)

*Source: Rosenbaum et al. 2019, Fig.1*

---

# Ajustement du modèle

&lt;img src="../images/Rosenbaum2019_Fig3.jpg" height="500"&gt;
*Source: Rosenbaum et al. 2019, Fig.3.*

---

# Ajustement du modèle

- Puisque la concentration d'azote `\(S\)` n'était pas mesurée, la précision de son estimation dépend de la précision des paramètres du modèle. Elle est moins précise quand les populations sont stables plutôt que cycliques (réplicats 10 à 12).

--

- Le modèle suit plus précisément les observations des concentrations d'algues.

--

- Explication possible: le modèle est plus "flexible" pour la conversion azote-algues car l'azote n'est pas mesuré, comparativement à la conversion algues-rotifères où les deux niveaux sont mesurés.

---

class: inverse, center, middle

# Application: dispersion des graines et semis

---

# Application: dispersion des graines et semis

- Marchand et al. (2020) Seed-to-seedling transitions exhibit distance-dependent mortality but no strong spacing effects in a Neotropical forest.

--

- But: Estimer les courbes de dispersion de graines et de semis en fonction de la distance du parent.

---

# Données

- Parcelle de 50 ha du Smithsonian Tropical Research Institute (île Barro Colorado, Panama).

--

- Arbres d'un DHP &gt;1cm cartographiés et mesurés aux 5 ans.

--

- Collecte annuelle des graines dans 500 capteurs (filets) et comptage des nouveaux semis dans des placettes près des capteurs.

--

- Modèle séparé pour chacune des principales espèces d'arbres.

---

# Modèle

- Nombre de graines dans le capteur `\(j\)` lors de l'année `\(t\)` suit une distribution binomiale négative, de moyenne:

`$$\mu_{jt} = a \sum_i Q(b_{it}) F(r_{ij})$$`

--

- `\(Q(b_{it})\)`: production de graines en fonction de la surface terrière de l'arbre `\(i\)` à l'année `\(t\)`.

--

- `\(F(r_{ij})\)`: fonction de dispersion, probabilité qu'une graine tombe dans une surface de 1 m&lt;sup&gt;2&lt;/sup&gt; située à distance `\(r_{ij}\)`.

--

- `\(a\)`: Aire du capteur.

---

# Modèle

Production de graines en fonction de la surface terrière:

`$$Q(b_{it}) = e^{\beta_t} b_{it}$$`

--

`$$\beta_t \sim \text{N}(\mu_{\beta}, \sigma_{\beta})$$`

---

# Modèle

Différentes fonctions de dispersion `\(F\)`

![](../images/Marchand2020_disp.png)

---

# Modèle

- Même modèle pour la dispersion des semis.

--

- Objectif: Déterminer la forme de la fonction de dispersion `\(F\)` pour les graines et semis de différentes espèces, ainsi que le succès relatif de germination (rapport entre le nombre de semis et de graines) en fonction de la distance du parent.

---

# Problèmes

- Nous n'observons pas la dispersion sur de longues distances ou très courtes distances. L'ajustement des fonctions de dispersion sans contrainte peut produire des résultats extrêmes.

--

- Il est probable qu'aucune des fonctions de dispersion utilisées ne corresponde tout à fait à la réalité, donc nous voulons que les résultats tiennent compte de cette incertitude sur la forme de la fonction de dispersion.

---

# Approche bayésienne

- Superposition de modèles utilisant chacune des 5 fonctions de dispersion pour obtenir des prédictions multi-modèles de la courbe de dispersion et du succès de germination en fonction de la distance.

--

- Vérifications *a posteriori* pour éliminer les modèles très mal ajustés au données.

--

- Distributions *a priori* pour les paramètres des fonctions de dispersion choisis pour que les valeurs plausibles de la distance médiane et moyenne de dispersion soient de l'ordre de 1 m à 1 km.

---

# Résultats

&lt;img src="../images/Marchand2020_res.png" height="500"&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
